"""
AIåˆ†ææ¨¡å— - ä½¿ç”¨LangChainè¿›è¡ŒåŸºé‡‘å¸‚åœºæ·±åº¦åˆ†æ

è¯¥æ¨¡å—æä¾›åŸºäºLangChainçš„AIåˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- å¸‚åœºè¶‹åŠ¿åˆ†æ
- æ¿å—æœºä¼šåˆ†æ
- åŸºé‡‘ç»„åˆå»ºè®®
- é£é™©æç¤ºåˆ†æ
"""

import os
import time
import datetime
import re
from loguru import logger


class AIAnalyzer:
    """AIåˆ†æå™¨ï¼Œæä¾›åŸºäºLangChainçš„å¸‚åœºåˆ†æåŠŸèƒ½"""

    def __init__(self):
        """åˆå§‹åŒ–AIåˆ†æå™¨"""
        self.llm = None

    def init_langchain_llm(self):
        """åˆå§‹åŒ–LangChain LLM"""
        try:
            from langchain_openai import ChatOpenAI

            # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
            api_base = os.getenv("LLM_API_BASE", "https://api.openai.com/v1")
            api_key = os.getenv("LLM_API_KEY", "")
            model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")

            if not api_key:
                logger.warning("æœªé…ç½®LLM_API_KEYç¯å¢ƒå˜é‡ï¼Œè·³è¿‡AIåˆ†æ")
                return None

            # åˆ›å»ºChatOpenAIå®ä¾‹
            llm = ChatOpenAI(
                model=model,
                openai_api_key=api_key,
                openai_api_base=api_base,
                temperature=0.7,
                max_tokens=2000,
                request_timeout=60
            )

            return llm

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–LangChain LLMå¤±è´¥: {e}")
            return None

    @staticmethod
    def strip_markdown(text):
        """ç§»é™¤markdownæ ¼å¼æ ‡è®°ï¼Œç”¨äºæ§åˆ¶å°æ˜¾ç¤º"""
        # ç§»é™¤æ ‡é¢˜ç¬¦å· (###ã€##ã€#)
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)

        # ç§»é™¤åŠ ç²— (**text** æˆ– __text__)
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
        text = re.sub(r'__(.+?)__', r'\1', text)

        # ç§»é™¤æ–œä½“ (*text* æˆ– _text_)
        text = re.sub(r'\*(.+?)\*', r'\1', text)
        text = re.sub(r'_(.+?)_', r'\1', text)

        # ç§»é™¤åˆ é™¤çº¿ (~~text~~)
        text = re.sub(r'~~(.+?)~~', r'\1', text)

        # ç§»é™¤ä»£ç å—æ ‡è®° (```)
        text = re.sub(r'```[\s\S]*?```', '', text)
        text = re.sub(r'`(.+?)`', r'\1', text)

        # ç§»é™¤é“¾æ¥ [text](url)
        text = re.sub(r'\[(.+?)\]\(.+?\)', r'\1', text)

        # ç§»é™¤åˆ—è¡¨æ ‡è®° (-, *, +, 1.)
        text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)

        # ç§»é™¤è¡¨æ ¼åˆ†éš”çº¿ (|---|---|)
        text = re.sub(r'\|[-:\s|]+\|', '', text)

        # ç®€åŒ–è¡¨æ ¼æ ¼å¼ (| cell |) -> cell
        text = re.sub(r'\s*\|\s*', ' ', text)

        # ç§»é™¤å¼•ç”¨æ ‡è®° (>)
        text = re.sub(r'^>\s+', '', text, flags=re.MULTILINE)

        # ç§»é™¤å¤šä½™ç©ºè¡Œ
        text = re.sub(r'\n\n+', '\n\n', text)

        return text.strip()

    @staticmethod
    def format_text(text, max_width=60):
        """å°†markdownæ–‡æœ¬è¿‡æ»¤å¹¶æ™ºèƒ½åˆ†è¡Œï¼Œç”¨äºæ§åˆ¶å°æ˜¾ç¤º"""
        # å…ˆè¿‡æ»¤markdownæ ¼å¼
        text = AIAnalyzer.strip_markdown(text)

        lines = []
        # å…ˆå»æ‰å¤šä½™çš„ç©ºè¡Œï¼Œåˆå¹¶æˆä¸€æ®µ
        text = " ".join(line.strip() for line in text.split("\n") if line.strip())

        # æŒ‰å¥å­åˆ†å‰²ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·ï¼‰
        current_line = ""
        for char in text:
            current_line += char
            # é‡åˆ°å¥å­ç»“æŸç¬¦å·ä¸”é•¿åº¦è¶…è¿‡30å­—ç¬¦ï¼Œæˆ–é•¿åº¦è¶…è¿‡max_width
            if (char in "ã€‚ï¼ï¼Ÿï¼›" and len(current_line) > 30) or len(current_line) >= max_width:
                lines.append(current_line.strip())
                current_line = ""

        # æ·»åŠ å‰©ä½™å†…å®¹
        if current_line.strip():
            lines.append(current_line.strip())

        return lines

    def analyze(self, data_collector):
        """
        æ‰§è¡ŒAIåˆ†æ

        Args:
            data_collector: æ•°æ®æ”¶é›†å™¨å¯¹è±¡ï¼Œéœ€è¦æä¾›ä»¥ä¸‹æ–¹æ³•ï¼š
                - get_market_info(is_return=True)
                - kx(is_return=True)
                - gold(is_return=True)
                - real_time_gold(is_return=True)
                - seven_A(is_return=True)
                - A(is_return=True)
                - bk(is_return=True)
                ä»¥åŠ self.result å’Œ self.CACHE_MAP å±æ€§
        """
        try:
            from langchain_core.prompts import ChatPromptTemplate
            from langchain_core.output_parsers import StrOutputParser

            logger.debug("æ­£åœ¨æ”¶é›†æ•°æ®è¿›è¡ŒAIåˆ†æ...")

            # åˆå§‹åŒ–LLM
            llm = self.init_langchain_llm()
            if llm is None:
                return

            # æ”¶é›†å¸‚åœºæ•°æ®
            market_data = data_collector.get_market_info(is_return=True)
            market_summary = "ä¸»è¦å¸‚åœºæŒ‡æ•°ï¼š\n"
            for item in market_data[:10]:
                market_summary += f"- {item[0]}: {item[1]} ({item[2]})\n"

            # æ”¶é›†7x24å¿«è®¯
            kx_data = data_collector.kx(is_return=True)
            kx_summary = "7Ã—24å¿«è®¯ï¼ˆæœ€æ–°10æ¡ï¼‰ï¼š\n"
            for i, v in enumerate(kx_data[:10], 1):
                evaluate = v.get("evaluate", "")
                evaluate_tag = f"ã€{evaluate}ã€‘" if evaluate else ""
                title = v.get("title", v.get("content", {}).get("items", [{}])[0].get("data", ""))
                publish_time = datetime.datetime.fromtimestamp(int(v["publish_time"])).strftime("%Y-%m-%d %H:%M:%S")
                entity = v.get("entity", [])
                if entity:
                    entity_str = ", ".join([f"{x['code']}-{x['name']}" for x in entity[:3]])  # æœ€å¤šæ˜¾ç¤º3åªè‚¡ç¥¨
                    kx_summary += f"{i}. {publish_time} {evaluate_tag}{title} (å½±å“: {entity_str})\n"
                else:
                    kx_summary += f"{i}. {publish_time} {evaluate_tag}{title}\n"

            # æ”¶é›†é‡‘ä»·æ•°æ®
            gold_data = data_collector.gold(is_return=True)
            gold_summary = "è¿‘æœŸé‡‘ä»·ï¼ˆæœ€è¿‘5å¤©ï¼‰ï¼š\n"
            for item in gold_data[:5]:
                gold_summary += f"- {item[0]}: ä¸­å›½é»„é‡‘{item[1]}, å‘¨å¤§ç¦{item[2]}, æ¶¨è·Œ({item[3]}, {item[4]})\n"

            # æ”¶é›†å®æ—¶é‡‘ä»·
            realtime_gold_data = data_collector.real_time_gold(is_return=True)
            realtime_gold_summary = "å®æ—¶é‡‘ä»·ï¼š\n"
            if realtime_gold_data and len(realtime_gold_data) == 2:
                for row in realtime_gold_data:
                    if row:
                        realtime_gold_summary += f"- {row[0]}: æœ€æ–°ä»·{row[1]}, æ¶¨è·Œå¹…{row[3]}\n"

            # æ”¶é›†è¿‘7æ—¥æˆäº¤é‡
            seven_a_data = data_collector.seven_A(is_return=True)
            seven_a_summary = "è¿‘7æ—¥æˆäº¤é‡ï¼ˆæœ€è¿‘3å¤©ï¼‰ï¼š\n"
            for item in seven_a_data[:3]:
                seven_a_summary += f"- {item[0]}: æ€»æˆäº¤{item[1]}, ä¸Šäº¤æ‰€{item[2]}, æ·±äº¤æ‰€{item[3]}, åŒ—äº¤æ‰€{item[4]}\n"

            # æ”¶é›†è¿‘30åˆ†é’Ÿä¸Šè¯æŒ‡æ•°
            a_data = data_collector.A(is_return=True)
            a_summary = "è¿‘30åˆ†é’Ÿä¸Šè¯æŒ‡æ•°ï¼ˆæœ€è¿‘5åˆ†é’Ÿï¼‰ï¼š\n"
            for item in a_data[-5:]:
                a_summary += f"- {item[0]}: {item[1]}, æ¶¨è·Œé¢{item[2]}, æ¶¨è·Œå¹…{item[3]}, æˆäº¤é‡{item[4]}, æˆäº¤é¢{item[5]}\n"

            # æ”¶é›†æ¿å—æ•°æ®
            bk_data = data_collector.bk(is_return=True)
            top_sectors = "æ¶¨å¹…å‰5æ¿å—ï¼š\n"
            for i, item in enumerate(bk_data[:5]):
                top_sectors += f"{i+1}. {item[0]}: {item[1]}, ä¸»åŠ›å‡€æµå…¥{item[2]}, ä¸»åŠ›æµå…¥å æ¯”{item[3]}\n"

            bottom_sectors = "è·Œå¹…å5æ¿å—ï¼š\n"
            for i, item in enumerate(bk_data[-5:]):
                bottom_sectors += f"{i+1}. {item[0]}: {item[1]}, ä¸»åŠ›å‡€æµå…¥{item[2]}, ä¸»åŠ›æµå…¥å æ¯”{item[3]}\n"

            # æ”¶é›†åŸºé‡‘æ•°æ®
            fund_data = []
            for fund_code, fund_info in data_collector.CACHE_MAP.items():
                for fund in data_collector.result:
                    if fund[0] == fund_code:
                        fund_data.append({
                            "code": fund[0],
                            "name": fund[1].replace("â­ ", "").replace("\033[1;31m", "").replace("\033[1;32m", ""),
                            "forecast": fund[3].replace("\033[1;31m", "").replace("\033[1;32m", ""),
                            "growth": fund[4].replace("\033[1;31m", "").replace("\033[1;32m", ""),
                            "consecutive": fund[5].replace("\033[1;31m", "").replace("\033[1;32m", ""),
                            "consecutive_growth": fund[6].replace("\033[1;31m", "").replace("\033[1;32m", ""),
                            "month_stats": fund[7],
                            "month_growth": fund[8].replace("\033[1;31m", "").replace("\033[1;32m", ""),
                            "is_hold": fund_info.get("is_hold", False)
                        })
                        break

            # æ„å»ºåŸºé‡‘æ‘˜è¦
            fund_summary = f"è‡ªé€‰åŸºé‡‘æ€»æ•°: {len(fund_data)}åª\n\n"

            # æŒæœ‰åŸºé‡‘
            hold_funds = [f for f in fund_data if f["is_hold"]]
            if hold_funds:
                fund_summary += "æŒæœ‰åŸºé‡‘ï¼š\n"
                for i, f in enumerate(hold_funds, 1):
                    fund_summary += f"{i}. {f['name']}: ä¼°å€¼{f['forecast']}, æ—¥æ¶¨å¹…{f['growth']}, è¿ç»­{f['consecutive']}å¤©, è¿‘30å¤©{f['month_stats']}\n"
                fund_summary += "\n"

            # è¡¨ç°æœ€å¥½çš„åŸºé‡‘
            top_funds = sorted(fund_data, key=lambda x: float(x["forecast"].replace("%", "")) if x["forecast"] != "N/A" else -999, reverse=True)[:5]
            fund_summary += "ä»Šæ—¥æ¶¨å¹…å‰5çš„åŸºé‡‘ï¼š\n"
            for i, f in enumerate(top_funds, 1):
                hold_mark = "ã€æŒæœ‰ã€‘" if f["is_hold"] else ""
                fund_summary += f"{i}. {hold_mark}{f['name']}: ä¼°å€¼{f['forecast']}, æ—¥æ¶¨å¹…{f['growth']}\n"

            # åˆ›å»ºæç¤ºé“¾ - å¸‚åœºè¶‹åŠ¿åˆ†æ
            trend_prompt = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯ä¸€ä½èµ„æ·±é‡‘èåˆ†æå¸ˆï¼Œæ“…é•¿å®è§‚å¸‚åœºåˆ†æå’Œè¶‹åŠ¿åˆ¤æ–­ã€‚è¯·ä»ä¸“ä¸šè§’åº¦æ·±å…¥åˆ†æå¸‚åœºèµ°åŠ¿ã€‚"),
                ("user", """è¯·åŸºäºä»¥ä¸‹å®Œæ•´çš„å¸‚åœºæ•°æ®ï¼Œè¿›è¡Œæ·±å…¥çš„å¸‚åœºè¶‹åŠ¿åˆ†æï¼š

ã€7Ã—24å¿«è®¯ã€‘
{kx_summary}

ã€å¸‚åœºæŒ‡æ•°ã€‘
{market_summary}

ã€é‡‘ä»·èµ°åŠ¿ã€‘
{gold_summary}

{realtime_gold_summary}

ã€å¸‚åœºæˆäº¤é‡ã€‘
{seven_a_summary}

ã€ä¸Šè¯åˆ†æ—¶æ•°æ®ã€‘
{a_summary}

ã€é¢†æ¶¨æ¿å—ã€‘
{top_sectors}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼ˆè¾“å‡º300-400å­—ï¼‰ï¼š
1. ç»“åˆ7Ã—24å¿«è®¯ï¼Œåˆ†æå½“å‰å¸‚åœºçƒ­ç‚¹å’Œé‡è¦äº‹ä»¶
2. åˆ†æä¸»è¦æŒ‡æ•°çš„èµ°åŠ¿ç‰¹å¾å’Œç›¸äº’å…³ç³»
3. åˆ¤æ–­å½“å‰å¸‚åœºæ‰€å¤„çš„é˜¶æ®µï¼ˆä¸Šæ¶¨/éœ‡è¡/è°ƒæ•´ï¼‰
4. åˆ†æå¸‚åœºæƒ…ç»ªå’Œèµ„é‡‘æµå‘ç‰¹å¾ï¼ˆç»“åˆæˆäº¤é‡å’Œåˆ†æ—¶æ•°æ®ï¼‰
5. å¯¹æ¯”å›½å†…å¤–å¸‚åœºè¡¨ç°ï¼ŒæŒ‡å‡ºå…³é”®å½±å“å› ç´ 
6. åˆ†æé‡‘ä»·èµ°åŠ¿å¯¹å¸‚åœºçš„å½±å“

è¯·ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€è¾“å‡ºï¼Œä½¿ç”¨markdownæ ¼å¼ï¼ˆå¯ä½¿ç”¨##ã€###æ ‡é¢˜ï¼Œ**åŠ ç²—**ï¼Œåˆ—è¡¨ï¼Œè¡¨æ ¼ç­‰ï¼‰ï¼Œè¾“å‡ºç»“æ„åŒ–ã€æ˜“è¯»çš„ä¸“ä¸šåˆ†ææŠ¥å‘Šã€‚""")
            ])

            # åˆ›å»ºæç¤ºé“¾ - æ¿å—æœºä¼šåˆ†æ
            sector_prompt = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯ä¸€ä½è¡Œä¸šç ”ç©¶ä¸“å®¶ï¼Œç²¾é€šå„ä¸ªè¡Œä¸šæ¿å—çš„æŠ•èµ„é€»è¾‘å’Œå‘¨æœŸè§„å¾‹ã€‚"),
                ("user", """è¯·åŸºäºä»¥ä¸‹æ¿å—æ•°æ®å’Œå¸‚åœºç¯å¢ƒï¼Œæ·±å…¥åˆ†æè¡Œä¸šæŠ•èµ„æœºä¼šï¼š

ã€æ¶¨å¹…é¢†å…ˆæ¿å—ã€‘
{top_sectors}

ã€è·Œå¹…æ¿å—ã€‘
{bottom_sectors}

ã€å¸‚åœºæˆäº¤é‡ã€‘
{seven_a_summary}

ã€ä¸Šè¯åˆ†æ—¶ã€‘
{a_summary}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼ˆè¾“å‡º300-400å­—ï¼‰ï¼š
1. åˆ†æé¢†æ¶¨æ¿å—çš„å…±åŒç‰¹å¾å’Œé©±åŠ¨å› ç´ 
2. åˆ¤æ–­è¿™äº›æ¿å—çš„è¡Œæƒ…å¯æŒç»­æ€§ï¼ˆç»“åˆæˆäº¤é‡å’Œèµ„é‡‘æµå‘ï¼‰
3. ç»“åˆèµ„é‡‘æµå…¥æƒ…å†µï¼Œè¯„ä¼°æ¿å—å¼ºåº¦
4. æç¤ºå“ªäº›æ¿å—å€¼å¾—é‡ç‚¹å…³æ³¨ï¼Œç»™å‡ºé…ç½®å»ºè®®
5. åˆ†æå¼±åŠ¿æ¿å—æ˜¯å¦å­˜åœ¨åè½¬æœºä¼š

è¯·ç”¨ä¸“ä¸šã€æ·±å…¥çš„è¯­è¨€è¾“å‡ºï¼Œä½¿ç”¨markdownæ ¼å¼ï¼ˆå¯ä½¿ç”¨##ã€###æ ‡é¢˜ï¼Œ**åŠ ç²—**ï¼Œåˆ—è¡¨ï¼Œè¡¨æ ¼ç­‰ï¼‰ï¼Œè¾“å‡ºç»“æ„åŒ–ã€æ˜“è¯»çš„ä¸“ä¸šåˆ†ææŠ¥å‘Šã€‚""")
            ])

            # åˆ›å»ºæç¤ºé“¾ - åŸºé‡‘ç»„åˆå»ºè®®
            portfolio_prompt = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŸºé‡‘æŠ•èµ„é¡¾é—®ï¼Œæ“…é•¿åŸºé‡‘ç»„åˆé…ç½®å’Œé£é™©ç®¡ç†ã€‚"),
                ("user", """è¯·åŸºäºä»¥ä¸‹åŸºé‡‘æŒä»“å’Œå®Œæ•´å¸‚åœºç¯å¢ƒï¼Œç»™å‡ºæŠ•èµ„å»ºè®®ï¼š

ã€åŸºé‡‘æŒä»“ã€‘
{fund_summary}

ã€å¸‚åœºç¯å¢ƒã€‘
{market_summary}

ã€å¸‚åœºæˆäº¤é‡ã€‘
{seven_a_summary}

ã€æ¿å—è¡¨ç°ã€‘
{top_sectors}

è¯·ä»ä»¥ä¸‹è§’åº¦ç»™å‡ºå»ºè®®ï¼ˆè¾“å‡º300-400å­—ï¼‰ï¼š
1. è¯„ä¼°å½“å‰æŒä»“åŸºé‡‘çš„è¡¨ç°å’Œé£é™©ç‰¹å¾
2. åˆ†ææŒä»“åŸºé‡‘ä¸å¸‚åœºç¯å¢ƒçš„åŒ¹é…åº¦ï¼ˆç»“åˆæˆäº¤é‡å’Œæ¿å—è½®åŠ¨ï¼‰
3. ç»™å‡ºå…·ä½“çš„è°ƒä»“å»ºè®®ï¼ˆå¢æŒ/å‡æŒ/æŒæœ‰ï¼‰
4. å¯¹è¡¨ç°ä¼˜å¼‚çš„åŸºé‡‘ï¼Œåˆ†æèƒŒååŸå› å’Œå¯æŒç»­æ€§
5. æç¤ºä»“ä½é…ç½®å’Œé£é™©æ•å£çš„ä¼˜åŒ–æ–¹å‘

è¯·ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ï¼Œä½¿ç”¨markdownæ ¼å¼ï¼ˆå¯ä½¿ç”¨##ã€###æ ‡é¢˜ï¼Œ**åŠ ç²—**ï¼Œåˆ—è¡¨ï¼Œè¡¨æ ¼ç­‰ï¼‰ï¼Œè¾“å‡ºç»“æ„åŒ–ã€æ˜“è¯»çš„ä¸“ä¸šåˆ†ææŠ¥å‘Šã€‚""")
            ])

            # åˆ›å»ºæç¤ºé“¾ - é£é™©æç¤º
            risk_prompt = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯ä¸€ä½é£é™©ç®¡ç†ä¸“å®¶ï¼Œæ“…é•¿è¯†åˆ«å¸‚åœºé£é™©å’Œåˆ¶å®šé£æ§ç­–ç•¥ã€‚"),
                ("user", """è¯·åŸºäºå½“å‰å®Œæ•´çš„å¸‚åœºæ•°æ®ï¼Œè¿›è¡Œå…¨é¢çš„é£é™©åˆ†æï¼š

ã€å¸‚åœºæŒ‡æ•°ã€‘
{market_summary}

ã€é‡‘ä»·èµ°åŠ¿ã€‘
{gold_summary}

ã€å¸‚åœºæˆäº¤é‡ã€‘
{seven_a_summary}

ã€ä¸Šè¯åˆ†æ—¶ã€‘
{a_summary}

ã€æ¿å—è¡¨ç°ã€‘
{top_sectors}
{bottom_sectors}

ã€åŸºé‡‘æŒä»“ã€‘
{fund_summary}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œé£é™©åˆ†æï¼ˆè¾“å‡º250-350å­—ï¼‰ï¼š
1. è¯†åˆ«å½“å‰å¸‚åœºçš„ä¸»è¦é£é™©ç‚¹ï¼ˆç»“åˆæˆäº¤é‡èç¼©/æ”¾å¤§ã€åˆ†æ—¶èµ°åŠ¿ç­‰ï¼‰
2. åˆ†æå¯èƒ½å¼•å‘è°ƒæ•´çš„è§¦å‘å› ç´ 
3. è¯„ä¼°æŒä»“åŸºé‡‘çš„é£é™©æš´éœ²
4. ç»™å‡ºé£é™©é˜²æ§å»ºè®®å’Œåº”å¯¹ç­–ç•¥
5. æç¤ºéœ€è¦å…³æ³¨çš„é£é™©ä¿¡å·ï¼ˆåŒ…æ‹¬æŠ€æœ¯é¢å’Œèµ„é‡‘é¢ï¼‰

è¯·å®¢è§‚ã€è°¨æ…åœ°æç¤ºé£é™©ï¼Œä½¿ç”¨markdownæ ¼å¼ï¼ˆå¯ä½¿ç”¨##ã€###æ ‡é¢˜ï¼Œ**åŠ ç²—**ï¼Œåˆ—è¡¨ï¼Œè¡¨æ ¼ç­‰ï¼‰ï¼Œè¾“å‡ºç»“æ„åŒ–ã€æ˜“è¯»çš„ä¸“ä¸šåˆ†ææŠ¥å‘Šã€‚""")
            ])

            # åˆ›å»ºè¾“å‡ºè§£æå™¨
            output_parser = StrOutputParser()

            # æ‰§è¡Œå››ä¸ªç»´åº¦çš„åˆ†æ
            logger.info("æ­£åœ¨è¿›è¡Œå¸‚åœºè¶‹åŠ¿åˆ†æ...")
            trend_chain = trend_prompt | llm | output_parser
            trend_analysis = trend_chain.invoke({
                "kx_summary": kx_summary,
                "market_summary": market_summary,
                "gold_summary": gold_summary,
                "realtime_gold_summary": realtime_gold_summary,
                "seven_a_summary": seven_a_summary,
                "a_summary": a_summary,
                "top_sectors": top_sectors
            })

            logger.info("æ­£åœ¨è¿›è¡Œæ¿å—æœºä¼šåˆ†æ...")
            sector_chain = sector_prompt | llm | output_parser
            sector_analysis = sector_chain.invoke({
                "top_sectors": top_sectors,
                "bottom_sectors": bottom_sectors,
                "seven_a_summary": seven_a_summary,
                "a_summary": a_summary
            })

            logger.info("æ­£åœ¨è¿›è¡ŒåŸºé‡‘ç»„åˆåˆ†æ...")
            portfolio_chain = portfolio_prompt | llm | output_parser
            portfolio_analysis = portfolio_chain.invoke({
                "fund_summary": fund_summary,
                "market_summary": market_summary,
                "seven_a_summary": seven_a_summary,
                "top_sectors": top_sectors
            })

            logger.info("æ­£åœ¨è¿›è¡Œé£é™©åˆ†æ...")
            risk_chain = risk_prompt | llm | output_parser
            risk_analysis = risk_chain.invoke({
                "market_summary": market_summary,
                "gold_summary": gold_summary,
                "seven_a_summary": seven_a_summary,
                "a_summary": a_summary,
                "top_sectors": top_sectors,
                "bottom_sectors": bottom_sectors,
                "fund_summary": fund_summary
            })

            # ç”Ÿæˆmarkdownæ–‡ä»¶å†…å®¹
            markdown_content = f"""# AIå¸‚åœºæ·±åº¦åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**ï¼š{time.strftime('%Y-%m-%d %H:%M')}

---

## ğŸ“Š åŸå§‹æ•°æ®æ¦‚è§ˆ

### 7Ã—24å¿«è®¯

{kx_summary}

### å¸‚åœºæŒ‡æ•°

{market_summary}

### é‡‘ä»·èµ°åŠ¿

{gold_summary}

{realtime_gold_summary}

### å¸‚åœºæˆäº¤é‡

{seven_a_summary}

### ä¸Šè¯æŒ‡æ•°åˆ†æ—¶ï¼ˆæœ€è¿‘5åˆ†é’Ÿï¼‰

{a_summary}

### æ¶¨å¹…é¢†å…ˆæ¿å—ï¼ˆTop 5ï¼‰

{top_sectors}

### è·Œå¹…æ¿å—ï¼ˆBottom 5ï¼‰

{bottom_sectors}

### åŸºé‡‘æŒä»“æƒ…å†µ

{fund_summary}

---

## 1ï¸âƒ£ å¸‚åœºæ•´ä½“è¶‹åŠ¿åˆ†æ

{trend_analysis}

---

## 2ï¸âƒ£ è¡Œä¸šæ¿å—æœºä¼šåˆ†æ

{sector_analysis}

---

## 3ï¸âƒ£ åŸºé‡‘ç»„åˆæŠ•èµ„å»ºè®®

{portfolio_analysis}

---

## 4ï¸âƒ£ é£é™©æç¤ºä¸åº”å¯¹

{risk_analysis}

---

ğŸ’¡ **æç¤º**ï¼šä»¥ä¸Šåˆ†æç”±AIç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚
"""

            # ä¿å­˜markdownæ–‡ä»¶
            if not os.path.exists("reports"):
                os.mkdir("reports")

            report_filename = f"reports/ai_analysis_{time.strftime('%Y%m%d_%H%M%S')}.md"
            with open(report_filename, "w", encoding="utf-8") as f:
                f.write(markdown_content)

            logger.info(f"âœ… AIåˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š{report_filename}")

            # è¾“å‡ºå®Œæ•´çš„AIåˆ†ææŠ¥å‘Š
            logger.critical(f"{time.strftime('%Y-%m-%d %H:%M')} ğŸ“Š AIå¸‚åœºæ·±åº¦åˆ†ææŠ¥å‘Š")
            logger.info("=" * 80)

            logger.info("1ï¸âƒ£ å¸‚åœºæ•´ä½“è¶‹åŠ¿åˆ†æ")
            logger.info("-" * 80)
            for line in self.format_text(trend_analysis):
                logger.info(line)

            logger.info("=" * 80)
            logger.info("2ï¸âƒ£ è¡Œä¸šæ¿å—æœºä¼šåˆ†æ")
            logger.info("-" * 80)
            for line in self.format_text(sector_analysis):
                logger.info(line)

            logger.info("=" * 80)
            logger.info("3ï¸âƒ£ åŸºé‡‘ç»„åˆæŠ•èµ„å»ºè®®")
            logger.info("-" * 80)
            for line in self.format_text(portfolio_analysis):
                logger.info(line)

            logger.info("=" * 80)
            logger.info("4ï¸âƒ£ é£é™©æç¤ºä¸åº”å¯¹")
            logger.info("-" * 80)
            for line in self.format_text(risk_analysis):
                logger.info(line)

            logger.info("=" * 80)
            logger.info("ğŸ’¡ æç¤ºï¼šä»¥ä¸Šåˆ†æç”±AIç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚")
            logger.info("=" * 80)

        except Exception as e:
            logger.error(f"AIåˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            logger.error(traceback.format_exc())
