import importlib
import threading
import json

import urllib3
from dotenv import load_dotenv
from flask import Flask, request, Response, stream_with_context
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage
from loguru import logger

import fund
from ai_analyzer import AIAnalyzer, search_news, fetch_webpage
from module_html import get_full_page_html

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

urllib3.disable_warnings()
urllib3.util.ssl_.DEFAULT_CIPHERS = ":".join(
    [
        "ECDHE+AESGCM",
        "ECDHE+CHACHA20",
        'ECDHE-RSA-AES128-SHA',
        'ECDHE-RSA-AES256-SHA',
        "RSA+AESGCM",
        'AES128-SHA',
        'AES256-SHA',
    ]
)

app = Flask(__name__)
analyzer = AIAnalyzer()


def get_real_time_data_context(user_message):
    """åç«¯æ™ºèƒ½è·å–ç›¸å…³æ•°æ®ï¼Œæ ¹æ®ç”¨æˆ·é—®é¢˜åˆ¤æ–­éœ€è¦å“ªäº›æ¿å—"""
    try:
        my_fund = fund.MaYiFund()
        context_parts = []

        # å®šä¹‰æ‰€æœ‰æ•°æ®æ¨¡å—åŠå…¶å…³é”®è¯
        data_modules = {
            'kx': {
                'name': '7*24å¿«è®¯',
                'func': my_fund.kx_html,
                'keywords': ['å¿«è®¯', 'æ–°é—»', 'news', 'æ¶ˆæ¯', 'åŠ¨æ€']
            },
            'marker': {
                'name': 'å…¨çƒæŒ‡æ•°',
                'func': my_fund.marker_html,
                'keywords': ['æŒ‡æ•°', 'ä¸Šè¯', 'æ·±è¯', 'æ’ç”Ÿ', 'é“ç¼æ–¯', 'nasdaq', 'çº³æ–¯è¾¾å…‹', 'market', 'index']
            },
            'real_time_gold': {
                'name': 'å®æ—¶è´µé‡‘å±',
                'func': my_fund.real_time_gold_html,
                'keywords': ['é»„é‡‘', 'ç™½é“¶', 'è´µé‡‘å±', 'gold', 'silver', 'é‡‘ä»·']
            },
            'gold': {
                'name': 'å†å²é‡‘ä»·',
                'func': my_fund.gold_html,
                'keywords': ['å†å²é‡‘ä»·', 'é‡‘ä»·èµ°åŠ¿', 'é‡‘ä»·è¶‹åŠ¿']
            },
            'seven_A': {
                'name': 'æˆäº¤é‡è¶‹åŠ¿',
                'func': my_fund.seven_A_html,
                'keywords': ['æˆäº¤é‡', 'äº¤æ˜“é‡', 'volume']
            },
            'A': {
                'name': 'ä¸Šè¯åˆ†æ—¶',
                'func': my_fund.A_html,
                'keywords': ['ä¸Šè¯åˆ†æ—¶', 'Aè‚¡åˆ†æ—¶', 'åˆ†æ—¶å›¾']
            },
            'fund': {
                'name': 'è‡ªé€‰åŸºé‡‘',
                'func': my_fund.fund_html,
                'keywords': ['åŸºé‡‘', 'æŒä»“', 'è‡ªé€‰', 'fund', 'æ”¶ç›Š', 'å‡€å€¼']
            },
            'bk': {
                'name': 'è¡Œä¸šæ¿å—',
                'func': my_fund.bk_html,
                'keywords': ['æ¿å—', 'è¡Œä¸š', 'sector', 'æ¶¨è·Œ', 'ä¸»åŠ›', 'å‡€æµå…¥']
            },
        }

        # æ™ºèƒ½åˆ¤æ–­éœ€è¦è·å–å“ªäº›æ¨¡å—
        modules_to_fetch = []
        user_lower = user_message.lower()

        for module_id, module_info in data_modules.items():
            # æ£€æŸ¥ç”¨æˆ·é—®é¢˜æ˜¯å¦åŒ…å«è¯¥æ¨¡å—çš„å…³é”®è¯
            if any(keyword in user_lower for keyword in module_info['keywords']):
                modules_to_fetch.append((module_id, module_info))

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å…³é”®è¯ï¼Œè·å–å¿«è®¯å’ŒåŸºé‡‘æ•°æ®ä½œä¸ºé»˜è®¤
        if not modules_to_fetch:
            modules_to_fetch = [
                ('kx', data_modules['kx']),
                ('fund', data_modules['fund']),
            ]
            logger.info(f"æœªåŒ¹é…åˆ°ç‰¹å®šå…³é”®è¯ï¼Œè·å–é»˜è®¤æ¨¡å—: å¿«è®¯ã€è‡ªé€‰åŸºé‡‘")
        else:
            logger.info(f"æ ¹æ®é—®é¢˜åŒ¹é…åˆ°æ¨¡å—: {[m[0] for m in modules_to_fetch]}")

        # è·å–åŒ¹é…çš„æ¨¡å—æ•°æ®
        for module_id, module_info in modules_to_fetch:
            try:
                html_content = module_info['func']()

                # æå–HTMLä¸­çš„æ–‡æœ¬å†…å®¹
                from html.parser import HTMLParser

                class HTMLTextExtractor(HTMLParser):
                    def __init__(self):
                        super().__init__()
                        self.text = []

                    def handle_data(self, data):
                        if data.strip():
                            self.text.append(data.strip())

                    def get_text(self):
                        return '\n'.join(self.text)

                parser = HTMLTextExtractor()
                parser.feed(html_content)
                text_content = parser.get_text()

                # æ·»åŠ åˆ°contextï¼Œä½¿ç”¨æ ‡è®°æ ¼å¼
                context_parts.append(f"\n=== {module_info['name']} ({module_id}) ===\n{text_content}")

                logger.debug(f"âœ“ è·å– {module_info['name']} æ•°æ®æˆåŠŸ ({len(text_content)} chars)")

            except Exception as e:
                logger.error(f"âœ— è·å– {module_info['name']} æ•°æ®å¤±è´¥: {e}")
                context_parts.append(f"\n=== {module_info['name']} ({module_id}) ===\næ•°æ®è·å–å¤±è´¥")

        full_context = '\n'.join(context_parts)
        logger.info(f"åç«¯æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_context)} chars")

        return full_context

    except Exception as e:
        logger.error(f"Failed to get real-time data: {e}")
        return "æ•°æ®è·å–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"


@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    user_message = data.get('message')
    history = data.get('history', [])
    # ä¸å†ä½¿ç”¨å‰ç«¯ä¼ é€’çš„contextï¼Œå…¨éƒ¨ç”±åç«¯è·å–

    def generate():
        try:
            llm = analyzer.init_langchain_llm(fast_mode=True)
            if not llm:
                yield f"data: {json.dumps({'error': 'LLM not initialized. Please check your API keys in .env file.'}, ensure_ascii=False)}\n\n"
                return

            # åç«¯æ™ºèƒ½è·å–ç›¸å…³æ•°æ®
            yield f"data: {json.dumps({'type': 'status', 'message': 'æ­£åœ¨è·å–ç›¸å…³æ•°æ®...'}, ensure_ascii=False)}\n\n"
            backend_context = get_real_time_data_context(user_message)

            # Bind tools to LLM
            tools = [search_news, fetch_webpage]
            llm_with_tools = llm.bind_tools(tools)

            messages = [
                SystemMessage(content="""You are a professional financial analyst assistant in a Bloomberg-like terminal Pro-Chat.

YOUR PRIMARY ROLE: ANALYZE & SUMMARIZE, NOT JUST DISPLAY DATA
- The user can already see all raw data on the page (tables, charts, prices)
- Your value is in ANALYSIS, INSIGHTS, and RECOMMENDATIONS
- DO NOT simply repeat table data unless user explicitly asks for specific data
- Instead, provide: trends, comparisons, opportunities, risks, actionable insights

AVAILABLE DATA IN CONTEXT:
The CONTEXT contains real-time data from relevant market modules:
1. ğŸ“° 7*24å¿«è®¯ (kx) - Financial news (look for market-moving events)
2. ğŸŒ å…¨çƒæŒ‡æ•° (marker) - Global indices (analyze trends across markets)
3. ğŸ’° å®æ—¶è´µé‡‘å± (real_time_gold) - Precious metals (identify price movements)
4. ğŸ“Š å†å²é‡‘ä»· (gold) - Historical gold trends
5. ğŸ“ˆ æˆäº¤é‡è¶‹åŠ¿ (seven_A) - Trading volume trends
6. ğŸ‡¨ğŸ‡³ ä¸Šè¯åˆ†æ—¶ (A) - Shanghai Composite intraday
7. ğŸ¯ è‡ªé€‰åŸºé‡‘ (fund) - User's fund watchlist **â† Analyze performance, winners/losers**
8. ğŸ­ è¡Œä¸šæ¿å— (bk) - Sector performance **â† Identify hot/cold sectors**

HOW TO RESPOND BASED ON QUESTION TYPE:

1. GENERAL QUESTIONS (e.g., "ä»Šå¤©å¸‚åœºæ€ä¹ˆæ ·ï¼Ÿ", "è‡ªé€‰åŸºé‡‘è¡¨ç°å¦‚ä½•ï¼Ÿ"):
   âœ“ DO: Provide high-level summary with key insights
   âœ“ DO: Highlight top performers and underperformers
   âœ“ DO: Mention noteworthy trends or patterns
   âœ— DON'T: List all funds/sectors in a table

2. SPECIFIC DATA REQUESTS (e.g., "xxxåŸºé‡‘ä»Šå¤©æ¶¨äº†å¤šå°‘ï¼Ÿ", "ç”µå­æ¿å—æ•°æ®"):
   âœ“ DO: Provide the specific data requested
   âœ“ DO: Add context (e.g., how it compares to others)
   âœ— DON'T: Ignore the request and give general summary

3. ANALYTICAL QUESTIONS (e.g., "å“ªäº›åŸºé‡‘å€¼å¾—å…³æ³¨ï¼Ÿ", "ä¸ºä»€ä¹ˆé»„é‡‘æ¶¨äº†ï¼Ÿ"):
   âœ“ DO: Deep analysis using CONTEXT data
   âœ“ DO: Cross-reference news with price movements
   âœ“ DO: Provide reasoning and evidence
   âœ— DON'T: Give shallow or generic answers

EXAMPLE RESPONSES:

âŒ BAD (just repeating data):
"è‡ªé€‰åŸºé‡‘æ•°æ®å¦‚ä¸‹ï¼š
æ˜“æ–¹è¾¾æ¶ˆè´¹è¡Œä¸š +1.2%
æ‹›å•†ä¸­è¯ç™½é…’ -0.8%
..."

âœ… GOOD (analysis & insights):
"<p style='color: #e0e0e0;'>ä»Šæ—¥ <span style='color: #42a5f5;'>è‡ªé€‰åŸºé‡‘</span> æ•´ä½“è¡¨ç°åˆ†åŒ–ï¼š</p>
<ul style='margin: 4px 0; padding-left: 20px; color: #e0e0e0;'>
  <li><span style='color: #4caf50; font-weight: bold;'>æ¶ˆè´¹æ¿å—åŸºé‡‘é¢†æ¶¨</span>ï¼ˆæ˜“æ–¹è¾¾æ¶ˆè´¹è¡Œä¸š +1.2%ï¼‰ï¼Œå—ç›Šäºæ¶ˆè´¹æ•°æ®å›æš–</li>
  <li><span style='color: #f44336;'>ç™½é…’æ¿å—æ‰¿å‹</span>ï¼ˆæ‹›å•†ä¸­è¯ç™½é…’ -0.8%ï¼‰ï¼Œä¸7*24å¿«è®¯ä¸­æåˆ°çš„è°ƒæ§æ”¿ç­–ç›¸å…³</li>
</ul>
<p style='color: #ffa726;'>å»ºè®®ï¼šå…³æ³¨æ¶ˆè´¹å¤è‹è¶‹åŠ¿ï¼Œç™½é…’çŸ­æœŸè°¨æ…</p>"

RESPONSE STRUCTURE GUIDELINES:
- Start with a clear summary (1-2 sentences)
- Provide 2-4 key insights with evidence from CONTEXT
- Use bullet points for clarity
- End with actionable suggestion (if appropriate)
- Keep total response under 300 words unless deep analysis requested

WHEN TO USE TOOLS:
- User explicitly asks to "search online" or "find latest news from internet"
- Question about events/companies NOT in CONTEXT at all
- CONTEXT data is insufficient to answer

WHEN NOT TO USE TOOLS:
- User asks about "è‡ªé€‰åŸºé‡‘", "è¡Œä¸šæ¿å—", "é»„é‡‘" - data is in CONTEXT!
- General market questions answerable from CONTEXT
- Avoid over-reliance on external searches

RESPONSE FORMATTING (DARK THEME - ULTRA COMPACT):
Use BRIGHT colors on dark background with MINIMAL spacing:
- Default text: <p style="color: #e0e0e0; margin: 1px 0; line-height: 1.2;">
- Headers: <h4 style="color: #ffffff; margin: 2px 0 1px 0; font-size: 0.95em; font-weight: 600; line-height: 1.1;">
- Positive: <span style="color: #4caf50; font-weight: bold;">
- Negative: <span style="color: #f44336; font-weight: bold;">
- Highlights: <span style="color: #ffa726;">
- Module names: <span style="color: #42a5f5;">

Use COMPACT lists/bullets:
- <ul style="margin: 1px 0; padding-left: 14px; color: #e0e0e0; line-height: 1.2;">
- <li style="margin: 0;">

CRITICAL HTML RULES:
- ALWAYS close all HTML tags properly (</p>, </ul>, </span>, etc.)
- Keep HTML structure simple and valid
- Avoid deeply nested tags
- Complete your entire response - don't cut off mid-sentence

CRITICAL SPACING RULES:
- margin: 1px (æè‡´ç´§å‡‘)
- line-height: 1.2 (æç´§è¡Œé«˜)
- Minimize empty <p> tags between sections
- Use inline <span> instead of separate <p> when possible
- NO extra spacing between elements

Only use tables if user asks for specific data comparison.

NEVER use white backgrounds (#fff) or dark text (#000) - invisible on dark theme!

Remember: You are an ANALYST, not a data displayer. Keep responses CONCISE and COMPACT. Provide insights, not raw tables.""")
            ]

            # Add history (last 5 messages)
            for msg in history[-5:]:
                content = msg.get('content', '')
                if not content or not content.strip():
                    continue

                if msg.get('role') == 'user':
                    messages.append(HumanMessage(content=content))
                else:
                    messages.append(AIMessage(content=content))

            # Add current context and user message
            combined_input = f"CONTEXT FROM PAGE (åç«¯å®æ—¶æ•°æ®):\n{backend_context}\n\nUSER QUESTION: {user_message}"
            messages.append(HumanMessage(content=combined_input))

            # Multi-turn tool calling loop
            max_iterations = 5
            iteration = 0

            while iteration < max_iterations:
                iteration += 1

                # Send status update
                yield f"data: {json.dumps({'type': 'status', 'message': f'Processing (step {iteration})...'}, ensure_ascii=False)}\n\n"

                # On last iteration, force answer without tools
                if iteration == max_iterations:
                    logger.debug(f"\n[Iteration {iteration}] Final iteration - forcing answer without tools")
                    # Add instruction to answer without more tool calls
                    messages.append(HumanMessage(content="Please provide your final answer now based on all the information gathered. Do not call any more tools."))
                    response = llm.invoke(messages)  # Use llm without tools
                else:
                    response = llm_with_tools.invoke(messages)

                # Check if LLM wants to call tools
                if response.tool_calls and iteration < max_iterations:
                    logger.debug(f"\n[Iteration {iteration}] LLM requested {len(response.tool_calls)} tool call(s)")

                    # Send tool call notification
                    tool_names = [tc["name"] for tc in response.tool_calls]
                    yield f"data: {json.dumps({'type': 'tool_call', 'tools': tool_names}, ensure_ascii=False)}\n\n"

                    messages.append(response)

                    # Execute all tool calls
                    for tool_call in response.tool_calls:
                        tool_name = tool_call["name"]
                        logger.debug(f"  â†’ Calling {tool_name} with args: {tool_call['args']}")

                        if tool_name == "search_news":
                            tool_result = search_news.invoke(tool_call["args"])
                        elif tool_name == "fetch_webpage":
                            tool_result = fetch_webpage.invoke(tool_call["args"])
                        else:
                            tool_result = f"Unknown tool: {tool_name}"

                        logger.debug(f"  â†’ Result preview: {str(tool_result)[:100]}...")

                        messages.append(ToolMessage(
                            content=str(tool_result),
                            tool_call_id=tool_call["id"],
                            name=tool_name
                        ))

                    continue

                else:
                    # No more tool calls, stream the final answer
                    logger.debug(f"\n[Iteration {iteration}] LLM generated final answer")

                    # Stream the content with dynamic chunk size based on length
                    content = response.content
                    content_length = len(content)

                    # Dynamic chunk size: longer content = larger chunks
                    if content_length < 500:
                        chunk_size = 30  # Small content, smaller chunks for effect
                    elif content_length < 2000:
                        chunk_size = 80  # Medium content
                    else:
                        chunk_size = 150  # Large content, bigger chunks for speed

                    logger.debug(f"Streaming {content_length} chars with chunk_size={chunk_size}")

                    for i in range(0, content_length, chunk_size):
                        chunk = content[i:i+chunk_size]
                        yield f"data: {json.dumps({'type': 'content', 'chunk': chunk}, ensure_ascii=False)}\n\n"

                    # Send completion signal
                    yield f"data: {json.dumps({'type': 'done'})}\n\n"
                    return

            # Max iterations reached
            logger.debug(f"\n[Warning] Max iterations ({max_iterations}) reached")
            yield f"data: {json.dumps({'type': 'error', 'message': 'Maximum iterations reached. Please try rephrasing your question.'})}\n\n"

        except Exception as e:
            logger.error(f"Chat error: {str(e)}")
            yield f"data: {json.dumps({'type': 'error', 'message': f'Error: {str(e)}'})}\n\n"

    return Response(stream_with_context(generate()), mimetype='text/event-stream', headers={
        'Cache-Control': 'no-cache',
        'X-Accel-Buffering': 'no'
    })


@app.route('/fund', methods=['GET'])
def get_fund():
    add = request.args.get("add")
    delete = request.args.get("delete")
    importlib.reload(fund)
    my_fund = fund.MaYiFund()
    if add:
        my_fund.add_code(add)
    if delete:
        my_fund.delete_code(delete)
    results = {}

    def fetch_html(_name, _func):
        results[_name] = _func()

    threads = []
    tasks = {
        'marker': my_fund.marker_html,
        'gold': my_fund.gold_html,
        "real_time_gold": my_fund.real_time_gold_html,
        'A': my_fund.A_html,
        'fund': my_fund.fund_html,
        "seven_A": my_fund.seven_A_html,
        "bk": my_fund.bk_html,
        "kx": my_fund.kx_html,
    }
    for name, func in tasks.items():
        func = tasks[name]
        thread = threading.Thread(target=fetch_html, args=(name, func))
        thread.start()
        threads.append(thread)
    for thread in threads:
        thread.join()
    tabs_data = [
        {"id": "kx", "title": "7*24å¿«è®¯", "content": results["kx"]},
        {"id": "marker", "title": "å…¨çƒæŒ‡æ•°", "content": results["marker"]},
        {"id": "real_time_gold", "title": "å®æ—¶è´µé‡‘å±", "content": results["real_time_gold"]},
        {"id": "gold", "title": "å†å²é‡‘ä»·", "content": results["gold"]},
        {"id": "seven_A", "title": "æˆäº¤é‡è¶‹åŠ¿", "content": results["seven_A"]},
        {"id": "A", "title": "ä¸Šè¯åˆ†æ—¶", "content": results["A"]},
        {"id": "fund", "title": "è‡ªé€‰åŸºé‡‘", "content": results["fund"]},
        {"id": "bk", "title": "è¡Œä¸šæ¿å—", "content": results["bk"]},
    ]
    html = get_full_page_html(tabs_data)
    return html


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8311)
