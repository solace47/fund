import importlib
import threading
import json

import urllib3
from dotenv import load_dotenv
from flask import Flask, request, Response, stream_with_context
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage
from loguru import logger

import fund
from ai_analyzer import AIAnalyzer, search_news, fetch_webpage
from module_html import get_full_page_html

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

urllib3.disable_warnings()
urllib3.util.ssl_.DEFAULT_CIPHERS = ":".join(
    [
        "ECDHE+AESGCM",
        "ECDHE+CHACHA20",
        'ECDHE-RSA-AES128-SHA',
        'ECDHE-RSA-AES256-SHA',
        "RSA+AESGCM",
        'AES128-SHA',
        'AES256-SHA',
    ]
)

app = Flask(__name__)
analyzer = AIAnalyzer()


def get_real_time_data_context(user_message, history):
    """åç«¯æ™ºèƒ½è·å–ç›¸å…³æ•°æ®ï¼Œä¼˜å…ˆä»å†å²å¯¹è¯ä¸­æå–ä¸Šä¸‹æ–‡ä¸»é¢˜"""
    try:
        my_fund = fund.MaYiFund()
        context_parts = []

        # å®šä¹‰æ‰€æœ‰æ•°æ®æ¨¡å—
        data_modules = {
            'kx': {
                'name': '7*24å¿«è®¯',
                'func': my_fund.kx_html,
                'keywords': ['å¿«è®¯', 'æ–°é—»', 'news', 'æ¶ˆæ¯', 'åŠ¨æ€']
            },
            'marker': {
                'name': 'å…¨çƒæŒ‡æ•°',
                'func': my_fund.marker_html,
                'keywords': ['æŒ‡æ•°', 'ä¸Šè¯', 'æ·±è¯', 'æ’ç”Ÿ', 'é“ç¼æ–¯', 'nasdaq', 'çº³æ–¯è¾¾å…‹', 'market', 'index']
            },
            'real_time_gold': {
                'name': 'å®æ—¶è´µé‡‘å±',
                'func': my_fund.real_time_gold_html,
                'keywords': ['é»„é‡‘', 'ç™½é“¶', 'è´µé‡‘å±', 'gold', 'silver', 'é‡‘ä»·']
            },
            'gold': {
                'name': 'å†å²é‡‘ä»·',
                'func': my_fund.gold_html,
                'keywords': ['å†å²é‡‘ä»·', 'é‡‘ä»·èµ°åŠ¿', 'é‡‘ä»·è¶‹åŠ¿']
            },
            'seven_A': {
                'name': 'æˆäº¤é‡è¶‹åŠ¿',
                'func': my_fund.seven_A_html,
                'keywords': ['æˆäº¤é‡', 'äº¤æ˜“é‡', 'volume']
            },
            'A': {
                'name': 'ä¸Šè¯åˆ†æ—¶',
                'func': my_fund.A_html,
                'keywords': ['ä¸Šè¯åˆ†æ—¶', 'Aè‚¡åˆ†æ—¶', 'åˆ†æ—¶å›¾']
            },
            'fund': {
                'name': 'è‡ªé€‰åŸºé‡‘',
                'func': my_fund.fund_html,
                'keywords': ['åŸºé‡‘', 'æŒä»“', 'è‡ªé€‰', 'fund', 'æ”¶ç›Š', 'å‡€å€¼']
            },
            'bk': {
                'name': 'è¡Œä¸šæ¿å—',
                'func': my_fund.bk_html,
                'keywords': ['æ¿å—', 'è¡Œä¸š', 'sector', 'æ¶¨è·Œ', 'ä¸»åŠ›', 'å‡€æµå…¥']
            },
        }

        # ä»å†å²å¯¹è¯ä¸­æå–ä¸»é¢˜å…³é”®è¯ï¼ˆæœ€è¿‘5æ¡ï¼‰
        history_text = ""
        user_questions = []  # ä¿å­˜ç”¨æˆ·å†å²é—®é¢˜

        for msg in history[-5:]:
            content = msg.get('content', '')
            if msg.get('role') == 'user':
                user_questions.append(content)
                history_text += " " + content
            elif msg.get('role') == 'assistant':
                # ä»HTMLä¸­æå–çº¯æ–‡æœ¬
                from html.parser import HTMLParser

                class HTMLTextExtractor(HTMLParser):
                    def __init__(self):
                        super().__init__()
                        self.text = []

                    def handle_data(self, data):
                        if data.strip():
                            self.text.append(data.strip())

                    def get_text(self):
                        return ' '.join(self.text)

                parser = HTMLTextExtractor()
                try:
                    parser.feed(content)
                    extracted = parser.get_text()
                    # è¿‡æ»¤æ‰çŠ¶æ€æ¶ˆæ¯
                    if len(extracted) > 50 and not any(word in extracted for word in ['AI Analyst is thinking', 'â³', 'Processing']):
                        history_text += " " + extracted
                except:
                    pass

        # åˆå¹¶å½“å‰é—®é¢˜å’Œå†å²æ–‡æœ¬è¿›è¡Œåˆ†æ
        combined_text = (history_text + " " + user_message).lower()

        logger.debug(f"Combined text for keyword matching: {combined_text[:200]}...")


        # æ™ºèƒ½åˆ¤æ–­éœ€è¦è·å–å“ªäº›æ¨¡å—
        modules_to_fetch = []
        for module_id, module_info in data_modules.items():
            # ä»å†å²+å½“å‰é—®é¢˜ä¸­æ£€æŸ¥å…³é”®è¯
            if any(keyword in combined_text for keyword in module_info['keywords']):
                modules_to_fetch.append((module_id, module_info))

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å…³é”®è¯ï¼Œè·å–æ ¸å¿ƒæ¨¡å—
        if not modules_to_fetch:
            modules_to_fetch = [
                ('kx', data_modules['kx']),
                ('bk', data_modules['bk']),
                ('fund', data_modules['fund']),
            ]
            logger.info(f"æœªä»å†å²åŒ¹é…åˆ°å…³é”®è¯ï¼Œè·å–æ ¸å¿ƒæ¨¡å—")
        else:
            logger.info(f"ä»å†å²+å½“å‰é—®é¢˜åŒ¹é…åˆ°æ¨¡å—: {[m[0] for m in modules_to_fetch]}")

        # è·å–åŒ¹é…çš„æ¨¡å—æ•°æ®
        from html.parser import HTMLParser

        class HTMLTextExtractor(HTMLParser):
            def __init__(self):
                super().__init__()
                self.text = []

            def handle_data(self, data):
                if data.strip():
                    self.text.append(data.strip())

            def get_text(self):
                return '\n'.join(self.text)

        for module_id, module_info in modules_to_fetch:
            try:
                html_content = module_info['func']()
                parser = HTMLTextExtractor()
                parser.feed(html_content)
                text_content = parser.get_text()
                context_parts.append(f"\n=== {module_info['name']} ({module_id}) ===\n{text_content}")
                logger.debug(f"âœ“ è·å– {module_info['name']} æ•°æ®æˆåŠŸ ({len(text_content)} chars)")
            except Exception as e:
                logger.error(f"âœ— è·å– {module_info['name']} æ•°æ®å¤±è´¥: {e}")
                context_parts.append(f"\n=== {module_info['name']} ({module_id}) ===\næ•°æ®è·å–å¤±è´¥")

        full_context = '\n'.join(context_parts)
        logger.info(f"åç«¯æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_context)} chars")

        return full_context

    except Exception as e:
        logger.error(f"Failed to get real-time data: {e}")
        return "æ•°æ®è·å–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"


@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    user_message = data.get('message')
    history = data.get('history', [])
    # ä¸å†ä½¿ç”¨å‰ç«¯ä¼ é€’çš„contextï¼Œå…¨éƒ¨ç”±åç«¯è·å–

    def generate():
        try:
            llm = analyzer.init_langchain_llm(fast_mode=True)
            if not llm:
                yield f"data: {json.dumps({'error': 'LLM not initialized. Please check your API keys in .env file.'}, ensure_ascii=False)}\n\n"
                return

            # åç«¯æ™ºèƒ½è·å–ç›¸å…³æ•°æ®
            yield f"data: {json.dumps({'type': 'status', 'message': 'æ­£åœ¨è·å–ç›¸å…³æ•°æ®...'}, ensure_ascii=False)}\n\n"
            backend_context = get_real_time_data_context(user_message, history)

            # Bind tools to LLM
            tools = [search_news, fetch_webpage]
            llm_with_tools = llm.bind_tools(tools)

            messages = [
                SystemMessage(content="""Financial analyst assistant. Answer questions directly with analysis.

â›” FORBIDDEN - Never output these:
"æ­£åœ¨æœç´¢" "æ­£åœ¨åˆ†æ" "æ­£åœ¨è·å–" "æ­£åœ¨æŸ¥è¯¢"
<div>æ­£åœ¨...</div> â† THIS BREAKS EVERYTHING!

âœ… CORRECT output example:
<p style='color:#e0e0e0;margin:1px 0;line-height:1.2'>å›½é‡‘é‡åŒ–åŸºé‡‘é…ç½®ç§‘æŠ€å’ŒåŒ»è¯æ¿å—ï¼Œä»Šæ—¥æ¶¨<span style='color:#4caf50;font-weight:bold'>+0.5%</span></p>

âŒ WRONG output example:
<div>æ­£åœ¨æœç´¢åŸºé‡‘ä¿¡æ¯...</div> â† NEVER DO THIS!

Your FIRST word must be actual content, not status!

Format (dark theme, compact):
- Text: <p style="color:#e0e0e0;margin:1px 0;line-height:1.2">
- Good: <span style="color:#4caf50;font-weight:bold">
- Bad: <span style="color:#f44336;font-weight:bold">
- List: <ul style="margin:1px 0;padding-left:14px;line-height:1.2"><li style="margin:0">

Context has: åŸºé‡‘(fund), æ¿å—(bk), å¿«è®¯(kx), æŒ‡æ•°, é‡‘ä»·

Provide insights, not raw tables. Use context data. If user says "å®ƒ", check history.""")
            ]

            # å¤„ç†å†å²æ¶ˆæ¯ - å‰ç«¯ç°åœ¨ä¼šå‘é€æ­£ç¡®çš„å†…å®¹
            logger.debug(f"Processing {len(history)} history messages")

            from html.parser import HTMLParser

            class HTMLTextExtractor(HTMLParser):
                def __init__(self):
                    super().__init__()
                    self.text = []

                def handle_data(self, data):
                    if data.strip():
                        self.text.append(data.strip())

                def get_text(self):
                    return ' '.join(self.text)

            # ç›´æ¥å¤„ç†å†å²æ¶ˆæ¯ï¼Œæå–HTMLä¸ºçº¯æ–‡æœ¬
            for idx, msg in enumerate(history[-10:]):  # å–æœ€è¿‘10æ¡
                role = msg.get('role', '')
                content = msg.get('content', '')

                if not content or not content.strip():
                    continue

                if role == 'user':
                    messages.append(HumanMessage(content=content))
                    logger.debug(f"[{idx}] Added user: {content[:50]}...")

                elif role == 'assistant':
                    # å¦‚æœæ˜¯HTMLï¼Œæå–çº¯æ–‡æœ¬ï¼›å¦åˆ™ç›´æ¥ä½¿ç”¨
                    clean_content = content
                    if '<' in content and '>' in content:
                        parser = HTMLTextExtractor()
                        try:
                            parser.feed(content)
                            extracted = parser.get_text()
                            if extracted and len(extracted) > 10:
                                clean_content = extracted
                        except:
                            pass  # ä¿ç•™åŸå§‹å†…å®¹

                    messages.append(AIMessage(content=clean_content))
                    logger.debug(f"[{idx}] Added assistant: {clean_content[:50]}...")

            logger.info(f"ğŸ“Š Loaded {len([m for m in messages if isinstance(m, HumanMessage)])} user messages, "
                       f"{len([m for m in messages if isinstance(m, AIMessage)])} assistant messages")


            # Add current context and user message
            combined_input = f"CONTEXT FROM PAGE (åç«¯å®æ—¶æ•°æ®):\n{backend_context}\n\nUSER QUESTION: {user_message}"
            messages.append(HumanMessage(content=combined_input))

            # Multi-turn tool calling loop
            max_iterations = 5
            iteration = 0

            while iteration < max_iterations:
                iteration += 1

                # Send status update
                yield f"data: {json.dumps({'type': 'status', 'message': f'Processing (step {iteration})...'}, ensure_ascii=False)}\n\n"

                # On last iteration, force answer without tools
                if iteration == max_iterations:
                    logger.debug(f"\n[Iteration {iteration}] Final iteration - forcing answer without tools")
                    # Add instruction to answer without more tool calls
                    messages.append(HumanMessage(content="Please provide your final answer now based on all the information gathered. Do not call any more tools."))
                    response = llm.invoke(messages)  # Use llm without tools
                else:
                    response = llm_with_tools.invoke(messages)

                # Check if LLM wants to call tools
                if response.tool_calls and iteration < max_iterations:
                    logger.debug(f"\n[Iteration {iteration}] LLM requested {len(response.tool_calls)} tool call(s)")

                    # Send tool call notification
                    tool_names = [tc["name"] for tc in response.tool_calls]
                    yield f"data: {json.dumps({'type': 'tool_call', 'tools': tool_names}, ensure_ascii=False)}\n\n"

                    messages.append(response)

                    # Execute all tool calls
                    for tool_call in response.tool_calls:
                        tool_name = tool_call["name"]
                        logger.debug(f"  â†’ Calling {tool_name} with args: {tool_call['args']}")

                        if tool_name == "search_news":
                            tool_result = search_news.invoke(tool_call["args"])
                        elif tool_name == "fetch_webpage":
                            tool_result = fetch_webpage.invoke(tool_call["args"])
                        else:
                            tool_result = f"Unknown tool: {tool_name}"

                        logger.debug(f"  â†’ Result preview: {str(tool_result)[:100]}...")

                        messages.append(ToolMessage(
                            content=str(tool_result),
                            tool_call_id=tool_call["id"],
                            name=tool_name
                        ))

                    continue

                else:
                    # No more tool calls, stream the final answer
                    logger.debug(f"\n[Iteration {iteration}] LLM generated final answer")

                    # Validate that the response is not a status message
                    content = response.content
                    content_length = len(content)

                    # Check if AI output contains forbidden status messages
                    forbidden_phrases = ['æ­£åœ¨æœç´¢', 'æ­£åœ¨åˆ†æ', 'æ­£åœ¨è·å–', 'æ­£åœ¨æŸ¥è¯¢', 'æ­£åœ¨è°ƒç”¨']
                    is_status_message = any(phrase in content for phrase in forbidden_phrases)

                    if is_status_message and iteration < max_iterations:
                        logger.warning(f"âš ï¸ AI output contains status message, rejecting and requesting proper analysis")
                        # Add a strong correction message
                        messages.append(AIMessage(content=content))
                        messages.append(HumanMessage(content="""STOP! Your previous response contained status messages like "æ­£åœ¨æœç´¢..." which is FORBIDDEN.
                        
You must provide ACTUAL ANALYSIS, not status messages. 

Example of what you should output:
<p style='color: #e0e0e0; margin: 1px 0; line-height: 1.2;'>å›½é‡‘é‡åŒ–åŸºé‡‘ä»Šæ—¥è¡¨ç°ç¨³å¥ï¼Œä¸»è¦é…ç½®ç”µå­ã€åŒ»è¯ç­‰æˆé•¿æ¿å—...</p>

Now provide your REAL analysis without any status messages."""))
                        # Force one more iteration
                        continue

                    # Content is valid, proceed with streaming
                    # Dynamic chunk size: longer content = larger chunks
                    if content_length < 500:
                        chunk_size = 30  # Small content, smaller chunks for effect
                    elif content_length < 2000:
                        chunk_size = 80  # Medium content
                    else:
                        chunk_size = 150  # Large content, bigger chunks for speed

                    logger.debug(f"Streaming {content_length} chars with chunk_size={chunk_size}")

                    for i in range(0, content_length, chunk_size):
                        chunk = content[i:i+chunk_size]
                        yield f"data: {json.dumps({'type': 'content', 'chunk': chunk}, ensure_ascii=False)}\n\n"

                    # Send completion signal
                    yield f"data: {json.dumps({'type': 'done'})}\n\n"
                    return

            # Max iterations reached
            logger.debug(f"\n[Warning] Max iterations ({max_iterations}) reached")
            yield f"data: {json.dumps({'type': 'error', 'message': 'Maximum iterations reached. Please try rephrasing your question.'})}\n\n"

        except Exception as e:
            logger.error(f"Chat error: {str(e)}")
            yield f"data: {json.dumps({'type': 'error', 'message': f'Error: {str(e)}'})}\n\n"

    return Response(stream_with_context(generate()), mimetype='text/event-stream', headers={
        'Cache-Control': 'no-cache',
        'X-Accel-Buffering': 'no'
    })


@app.route('/fund/sector', methods=['GET'])
def get_sector_funds():
    """è·å–æŒ‡å®šæ¿å—çš„åŸºé‡‘åˆ—è¡¨"""
    bk_id = request.args.get("bk_id")
    importlib.reload(fund)
    my_fund = fund.MaYiFund()
    return my_fund.select_fund_html(bk_id=bk_id)


@app.route('/fund', methods=['GET'])
def get_fund():
    add = request.args.get("add")
    delete = request.args.get("delete")
    importlib.reload(fund)
    my_fund = fund.MaYiFund()
    if add:
        my_fund.add_code(add)
    if delete:
        my_fund.delete_code(delete)
    results = {}

    def fetch_html(_name, _func):
        try:
            results[_name] = _func()
            logger.debug(f"âœ“ Successfully fetched {_name}")
        except Exception as e:
            logger.error(f"âœ— Failed to fetch {_name}: {e}")
            results[_name] = f"<p style='color:#f44336;'>æ•°æ®åŠ è½½å¤±è´¥: {str(e)}</p>"

    threads = []
    tasks = {
        'marker': my_fund.marker_html,
        'gold': my_fund.gold_html,
        "real_time_gold": my_fund.real_time_gold_html,
        'A': my_fund.A_html,
        'fund': my_fund.fund_html,
        "seven_A": my_fund.seven_A_html,
        "bk": my_fund.bk_html,
        "kx": my_fund.kx_html,
        "select_fund": my_fund.select_fund_html,
    }
    for name, func in tasks.items():
        thread = threading.Thread(target=fetch_html, args=(name, func))
        thread.start()
        threads.append(thread)
    for thread in threads:
        thread.join()

    # Ensure all keys exist with fallback content
    for name in tasks.keys():
        if name not in results:
            logger.warning(f"âš ï¸ Missing result for {name}, using fallback")
            results[name] = f"<p style='color:#ff9800;'>æ•°æ®æœªåŠ è½½</p>"

    tabs_data = [
        {"id": "kx", "title": "7*24å¿«è®¯", "content": results["kx"]},
        {"id": "marker", "title": "å…¨çƒæŒ‡æ•°", "content": results["marker"]},
        {"id": "real_time_gold", "title": "å®æ—¶è´µé‡‘å±", "content": results["real_time_gold"]},
        {"id": "gold", "title": "å†å²é‡‘ä»·", "content": results["gold"]},
        {"id": "seven_A", "title": "æˆäº¤é‡è¶‹åŠ¿", "content": results["seven_A"]},
        {"id": "A", "title": "ä¸Šè¯åˆ†æ—¶", "content": results["A"]},
        {"id": "fund", "title": "è‡ªé€‰åŸºé‡‘", "content": results["fund"]},
        {"id": "bk", "title": "è¡Œä¸šæ¿å—", "content": results["bk"]},
        {"id": "select_fund", "title": "æ¿å—åŸºé‡‘æŸ¥è¯¢", "content": results["select_fund"]},
    ]
    html = get_full_page_html(tabs_data)
    return html


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8311)
